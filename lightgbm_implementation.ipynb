{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBuB6oFNwZaBmUnFPdXddY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Agalea96/lightgbm/blob/main/lightgbm_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYC-PjHnUKWX"
      },
      "outputs": [],
      "source": [
        "from pickle import TRUE\n",
        "# importing all needed libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm\n",
        "import sklearn.model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# input dataset\n",
        "df_train = pd.read_csv('/content/Traffic_Violation_Clean.csv', low_memory=False)\n",
        "def enc_labels(label):\n",
        "    return label_encoder.fit_transform(df_train[label])\n",
        "df_train.drop(columns=['Year', 'Year Stopped', 'DateTime Of Stop', 'Geolocation'])\n",
        "cat_features=df_train.select_dtypes(include=['object', 'int32']).columns\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for x in cat_features:\n",
        "    df_train['encoded_' + x] = enc_labels(x)\n",
        "filtered_columns=df_train.select_dtypes(include=['bool','int32','int64','float64'])\n",
        "\n",
        "# selecting all columns that are not the 'ID code' and 'target' columns\n",
        "var_columns = [c for c in filtered_columns.columns if c not in ['encoded_Violation Type']]\n",
        "\n",
        "# defining inputs as X labels as Y\n",
        "X = filtered_columns.loc[:,var_columns]\n",
        "Y = filtered_columns.loc[:,'encoded_Violation Type']\n",
        "\n",
        "# splitting training data and labels into training data and labels and validation data and labels\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=42)\n",
        "\n",
        "# setting up training and validation data so that they can be read by the lightgbm module\n",
        "train_data = lightgbm.Dataset(X_train, label = Y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 5\n",
        "\n",
        "kf = sklearn.model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "metrics = []"
      ],
      "metadata": {
        "id": "blMwoNjTilEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up parameters\n",
        "model_lgbm = lightgbm.LGBMClassifier(boosting_type='dart',\n",
        "                                     objective='multiclass',\n",
        "#parameters to increase accuracy\n",
        "                                     learning_rate=0.05,\n",
        "                                     num_iterations=200,\n",
        "#parameters to increase accuracy. WARNING, MIGHT CAUSE OVERFITTING\n",
        "                                     num_leaves=31,\n",
        "                                     max_bin=255,\n",
        "#parameters to reduce the chance of overfitting\n",
        "                                     min_child_samples=20,\n",
        "                                     min_child_weight=0.001,\n",
        "                                     subsample=1.0,\n",
        "                                     subsample_freq=0,\n",
        "                                     colsample_bytree=1.0,\n",
        "                                     extra_trees=True,\n",
        "                                     path_smooth=0,\n",
        "                                     max_depth=-1,\n",
        "\n",
        "                                     n_estimators=100,\n",
        "                                     subsample_for_bin=200000,\n",
        "                                     class_weight=None,\n",
        "                                     min_split_gain=0.0,\n",
        "                                     reg_alpha=0.0,\n",
        "                                     reg_lambda=0.0,\n",
        "                                     random_state=None,\n",
        "                                     n_jobs=None,\n",
        "                                     importance_type='split',\n",
        "                                     force_col_wise=True)"
      ],
      "metadata": {
        "id": "02gGvBfpeZYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform K-Fold Cross-Validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]"
      ],
      "metadata": {
        "id": "avWQKhhAkOdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit predictions to training, validation and test data\n",
        "Y_train_pred = model_lgbm.fit(X_train,Y_train)\n",
        "Y_test_pred = model_lgbm.fit(X_test,Y_test)\n",
        "\n",
        "# run predictions on training, validation and test models\n",
        "Y_train_pred = model_lgbm.predict(X_train, raw_score=False, start_iteration=0, num_iteration=None, pred_leaf=False, pred_contrib=False, validate_features=False)\n",
        "Y_test_pred = model_lgbm.predict(X_test, raw_score=False, start_iteration=0, num_iteration=None, pred_leaf=False, pred_contrib=False, validate_features=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPiyAmJovl_0",
        "outputId": "979df692-b4be-441e-b478-20a6146b7f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Total Bins 1670\n",
            "[LightGBM] [Info] Number of data points in the train set: 732395, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score -0.946695\n",
            "[LightGBM] [Info] Start training from score -3.321518\n",
            "[LightGBM] [Info] Start training from score -8.092429\n",
            "[LightGBM] [Info] Start training from score -0.552386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Total Bins 1660\n",
            "[LightGBM] [Info] Number of data points in the train set: 183098, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score -0.938117\n",
            "[LightGBM] [Info] Start training from score -3.324013\n",
            "[LightGBM] [Info] Start training from score -8.147485\n",
            "[LightGBM] [Info] Start training from score -0.558025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate classification reports for training, validation and test results\n",
        "report = classification_report(Y_train_pred,Y_train)\n",
        "print('Classification report (Training set):\\n', report)\n",
        "\n",
        "#report = classification_report(Y_valid_pred,Y_valid)\n",
        "print('Classification report (Validation set):\\n', report)\n",
        "\n",
        "#report = classification_report(Y_test_pred,Y_test)\n",
        "print('Classification report (Test set):\\n', report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weJfeVOdq6IY",
        "outputId": "6f098a22-5100-4e2c-8be4-caff91fa14d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report (Training set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.84    267580\n",
            "           1       0.78      0.91      0.84     22622\n",
            "           2       0.01      0.05      0.01        44\n",
            "           3       0.91      0.86      0.89    442149\n",
            "\n",
            "    accuracy                           0.86    732395\n",
            "   macro avg       0.63      0.67      0.64    732395\n",
            "weighted avg       0.87      0.86      0.87    732395\n",
            "\n",
            "Classification report (Validation set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.84    267580\n",
            "           1       0.78      0.91      0.84     22622\n",
            "           2       0.01      0.05      0.01        44\n",
            "           3       0.91      0.86      0.89    442149\n",
            "\n",
            "    accuracy                           0.86    732395\n",
            "   macro avg       0.63      0.67      0.64    732395\n",
            "weighted avg       0.87      0.86      0.87    732395\n",
            "\n",
            "Classification report (Test set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.86      0.84    267580\n",
            "           1       0.78      0.91      0.84     22622\n",
            "           2       0.01      0.05      0.01        44\n",
            "           3       0.91      0.86      0.89    442149\n",
            "\n",
            "    accuracy                           0.86    732395\n",
            "   macro avg       0.63      0.67      0.64    732395\n",
            "weighted avg       0.87      0.86      0.87    732395\n",
            "\n"
          ]
        }
      ]
    }
  ]
}